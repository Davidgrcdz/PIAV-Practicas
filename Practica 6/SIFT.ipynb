{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autenticación de huellas (Biometría) - SIFT\n",
    "En esta hipótesis hemos propuesto hacer uso del detector de características SIFT para tratar de autenticar a usuarios en una base de datos a través de sus huellas dactilares, obteniendo patrones y características clave de las huellas para posteriormente corroborarlas con nuestra base de datos y verificar si pertencen o no a nuestro sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de las imágenes de las huellas\n",
    "El preprocesamiento de las imágenes de las huellas incluye dos pasos principales: recorte y filtrado.\n",
    "1. Recorte: Se localiza el contorno más grande en cada imagen, que corresponde a la huella, y se recorta para eliminar bordes innecesarios y centrarse en las áreas importantes. Esto permite trabajar con imágenes uniformes y enfocadas.\n",
    "\n",
    "2. Filtrado: Para mejorar la calidad de las huellas y resaltar sus detalles clave, se aplicaron varias técnicas:\n",
    "    - Ecualización con CLAHE para mejorar el contraste en áreas oscuras.\n",
    "    - Filtro bilateral para suavizar sin perder bordes importantes.\n",
    "    - Filtro de mediana para eliminar ruido sin degradar líneas finas.\n",
    "    - Binarización adaptativa para segmentar crestas y valles bajo distintas condiciones de iluminación.\n",
    "    - Limpieza morfológica para eliminar ruido.\n",
    "    - Esqueletonizado para reducir la huella a su estructura básica y facilitar el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recortar_imagen(input_folder, output_folder, crop_width=550, crop_height=550, threshold_value=225):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if not file.endswith(('.png', '.jpg', '.jpeg')): \n",
    "                continue\n",
    "\n",
    "            img_path = os.path.join(root, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if img is None:\n",
    "                print(f\"Error al leer la imagen {img_path}\")\n",
    "                continue\n",
    "\n",
    "            # Binarización de la imagen\n",
    "            _, thresh = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "            # Encontramos los contornos\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            if contours:\n",
    "                # Seleccionamos el contorno más grande\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "                # Calcula el rectángulo para el contorno\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "                center_x, center_y = x + w // 2, y + h // 2\n",
    "\n",
    "                # Coordenadas para recortar la imagen\n",
    "                x_start = max(center_x - crop_width // 2, 0)\n",
    "                y_start = max(center_y - crop_height // 2, 0)\n",
    "                x_end = min(center_x + crop_width // 2, img.shape[1])\n",
    "                y_end = min(center_y + crop_height // 2, img.shape[0])\n",
    "\n",
    "                if (x_end - x_start) != crop_width:\n",
    "                    x_start = max(0, x_end - crop_width)\n",
    "                if (y_end - y_start) != crop_height:\n",
    "                    y_start = max(0, y_end - crop_height)\n",
    "\n",
    "                # Recorte\n",
    "                cropped_img = img[y_start:y_end, x_start:x_end]\n",
    "\n",
    "                output_path = os.path.join(output_folder, file)\n",
    "                cv2.imwrite(output_path, cropped_img)\n",
    "                print(f\"Imagen recortada guardada en {output_path}\")\n",
    "\n",
    "input_folder = 'imagenes_huellas'   \n",
    "output_folder = 'imagenes_recortadas' \n",
    "\n",
    "recortar_imagen(input_folder, output_folder)\n",
    "\n",
    "img = cv2.imread('imagenes_recortadas/11f_01.png', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_imagen(image_path, output_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"Error: No se pudo cargar la imagen {image_path}.\")\n",
    "        return\n",
    "    \n",
    "    # Ecualización de histograma local con CLAHE para mejorar el contraste\n",
    "    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8, 8))\n",
    "    equalized_image = clahe.apply(image)\n",
    "    \n",
    "    # Filtrado bilateral para suavizar la imagen y quedarnos con los bordes\n",
    "    bilateral_filtered = cv2.bilateralFilter(equalized_image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    \n",
    "    # Filtrado de mediana para eliminar ruido\n",
    "    median_filtered = cv2.medianBlur(bilateral_filtered, 3)\n",
    "    \n",
    "    # Binarización para quedarnos con las crestas y valles de la huella\n",
    "    thresh_image = cv2.adaptiveThreshold(\n",
    "        median_filtered,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        19,\n",
    "        3\n",
    "    )\n",
    "    \n",
    "    # Invierte la imagen binaria\n",
    "    inverted_image = cv2.bitwise_not(thresh_image)\n",
    "    \n",
    "    # Elimina pequeños puntos blancos\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned_image = cv2.morphologyEx(inverted_image, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Esqueletonización para reducir la huella a líneas de un píxel\n",
    "    skeleton = np.zeros(cleaned_image.shape, np.uint8)\n",
    "    img = cleaned_image.copy()\n",
    "    while True:\n",
    "        eroded = cv2.erode(img, None)  \n",
    "        temp = cv2.dilate(eroded, None)  \n",
    "        temp = cv2.subtract(img, temp) \n",
    "        skeleton = cv2.bitwise_or(skeleton, temp)  \n",
    "        img = eroded.copy()\n",
    "        if cv2.countNonZero(img) == 0:  \n",
    "            break\n",
    "\n",
    "    cv2.imwrite(output_path, skeleton)\n",
    "    print(f\"Imagen procesada y guardada en {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "input_dir = 'imagenes_recortadas'  \n",
    "output_dir = 'imagenes_filtradas' \n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):  \n",
    "            image_path = os.path.join(root, file)\n",
    "            output_path = os.path.join(output_dir, file)\n",
    "            \n",
    "            procesar_imagen(image_path, output_path)\n",
    "          \n",
    "\n",
    "img = cv2.imread('imagenes_filtradas/11f_01.png', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de la base de datos del sistema\n",
    "En este pequeño código creamos la base de datos **user_database** a partir de las huellas recién filtradas, que se va a utilizar para comprobar la autenticación de una huella respecto a los usuarios, de manera que la base de datos está dividida en subcarpetas por nombres de cada usuario, las cuales contienen ambas huellas de estos últimos (s y f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'imagenes_filtradas'\n",
    "output_dir = 'user_database'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Organizamos las imágenes en carpetas por usuario\n",
    "for image_name in os.listdir(input_dir):\n",
    "    if image_name.endswith('.png'):\n",
    "        user_id = image_name[:2]\n",
    "        user_dir = os.path.join(output_dir, f\"user{user_id}\")\n",
    "        os.makedirs(user_dir, exist_ok=True)\n",
    "        shutil.copy(os.path.join(input_dir, image_name), os.path.join(user_dir, image_name))\n",
    "\n",
    "print(\"Base de datos creada con éxito.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "Para aumentar el número de muestras del conjunto de datos, creamos una nueva carpeta **user_prueba**, en la cual se guardarán las muestras nuevas tras haber aplicado data augmentation generando variaciones aleatorias de las imágenes originales. Estas transformaciones incluyen rotación (ángulos aleatorios), escalado (cambios de tamaño), cortes parciales (simulando imágenes incompletas de posibles fallos al escanearlas) y traslación (desplazamientos aleatorios), donde cada imagen aumentada se guarda en el mismo directorio con un nombre modificado, enriqueciendo el conjunto de datos y mejorando la robustez del modelo ante variaciones comunes en huellas dactilares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_images(input_dir, output_dir, num_images):\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    images = [f for f in os.listdir(input_dir) if f.endswith('.png')]\n",
    "    \n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(input_dir, image_name)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            img_copy = img.copy()\n",
    "            \n",
    "            # Rotación aleatoria\n",
    "            angle = random.randint(-360, 360)\n",
    "            h, w = img_copy.shape\n",
    "            center = (w // 2, h // 2)\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            augmented_img = cv2.warpAffine(img_copy, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "            \n",
    "            # Escalado aleatorio\n",
    "            scale_x = random.uniform(0.5, 1.2)\n",
    "            scale_y = random.uniform(0.5, 1.2)\n",
    "            augmented_img = cv2.resize(augmented_img, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            # Corte parcial (simulando mal contacto)\n",
    "            x1, y1 = random.randint(0, w // 8), random.randint(0, h // 8)\n",
    "            x2, y2 = random.randint(x1, w // 4), random.randint(y1, h // 4)\n",
    "            cv2.rectangle(augmented_img, (x1, y1), (x2, y2), (0, 0, 0), -1)\n",
    "            \n",
    "            # Traslación aleatoria\n",
    "            max_shift = 10 \n",
    "            tx = random.randint(-max_shift, max_shift)\n",
    "            ty = random.randint(-max_shift, max_shift)\n",
    "            translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "            augmented_img = cv2.warpAffine(augmented_img, translation_matrix, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "            \n",
    "            output_name = f\"{i}_{image_name}\"\n",
    "            cv2.imwrite(os.path.join(output_dir, output_name), augmented_img)\n",
    "\n",
    "\n",
    "input_dir = 'imagenes_filtradas'\n",
    "output_dir = 'user_prueba'\n",
    "new_images(input_dir, output_dir, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción y detección de características\n",
    "Definimos dos métodos: uno para extraer características de las huellas usando SIFT y otro para compararlas. El primero detecta puntos clave y descriptores únicos, mientras que el segundo utiliza Brute-Force Matcher y KNN para contar las coincidencias válidas entre descriptores, aplicando un umbral para filtrar las mejores coincidencias. Esto permite evaluar la similitud entre dos huellas dactilares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_path):\n",
    "    # Extrae puntos clave y descriptores usando SIFT\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        return None\n",
    "    sift = cv2.SIFT_create()\n",
    "    _, descriptors = sift.detectAndCompute(image, None)\n",
    "    return descriptors\n",
    "\n",
    "def match_fingerprints(des1, des2, ratio_threshold=0.75):\n",
    "    # Compara dos conjuntos de descriptores SIFT y devuelve las coincidencias\n",
    "    if des1 is None or des2 is None:\n",
    "        return 0\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    good_matches = [m for m, n in matches if m.distance < ratio_threshold * n.distance]\n",
    "    return len(good_matches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de la base de datos\n",
    "El método **evaluate_database** compara imágenes de prueba con una base de datos usando SIFT, registrando el máximo número de coincidencias entre descriptores. Asigna etiquetas reales (1 para autenticadas si el nombre contiene \"s\" o \"f\", y 0 en caso contrario) y devuelve los puntajes de coincidencia, permitiendo evaluar el rendimiento del sistema de autenticación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_database(database_dir, test_dir, match_threshold=20):\n",
    "    # Evalúa las huellas y devuelve las etiquetas reales y los puntajes\n",
    "    true_labels = []\n",
    "    scores = []\n",
    "\n",
    "    for test_image in os.listdir(test_dir):\n",
    "        test_path = os.path.join(test_dir, test_image)\n",
    "        test_des = extract_features(test_path)\n",
    "\n",
    "        max_matches = 0\n",
    "        for user_folder in os.listdir(database_dir):\n",
    "            user_path = os.path.join(database_dir, user_folder)\n",
    "            for db_image in os.listdir(user_path):\n",
    "                db_path = os.path.join(user_path, db_image)\n",
    "                db_des = extract_features(db_path)\n",
    "\n",
    "                # Comparar descriptores y mantener el máximo\n",
    "                matches = match_fingerprints(test_des, db_des)\n",
    "                max_matches = max(max_matches, matches)\n",
    "\n",
    "        # Etiquetar como autenticada si contiene \"s\" o \"f\", de lo contrario es rechazada\n",
    "        true_labels.append(1 if \"s\" in test_image or \"f\" in test_image else 0)\n",
    "        scores.append(max_matches)\n",
    "\n",
    "    return true_labels, scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de coincidencias entre huellas\n",
    "\n",
    "Creamos una función a parte para poder visualizar las coincidencias existentes entre dos huellas, de manera que se puede utilizar en caso de que introduzcamos una nueva huella ajena a nuestra base de datos y queramos comprobar visualmente si existen o no coincidencias para la autenticación, entre las huellas en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_matches(image1_path, image2_path, ratio_threshold=0.75):\n",
    "    img1 = cv2.imread(image1_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img2 = cv2.imread(image2_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Extraer puntos clave y descriptores SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Realiza la comparación de descriptores\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "    good_matches = [m for m, n in matches if m.distance < ratio_threshold * n.distance]\n",
    "\n",
    "    # Dibuja las coincidencias\n",
    "    match_img = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(match_img, cmap='gray')\n",
    "    plt.title(f\"Coincidencias: {len(good_matches)}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autenticación de huellas\n",
    "Desarrollamos un método, **authenticate_user**, para autenticar una nueva huella comparándola con una base de datos organizada por usuarios. El método extrae características SIFT de la huella nueva y las compara con las de cada imagen en la base de datos, registrando el usuario con el mayor número de coincidencias. Si el número de coincidencias supera un umbral definido (por defecto, 100), la huella se autentica como perteneciente a ese usuario, en caso contrario, se rechaza la huella, de manera que el método devuelve el resultado de la autenticación junto con el número de coincidencias encontradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_user(new_fingerprint_path, database_dir, match_threshold=100):\n",
    "    # Compara una nueva huella con la base de datos organizada por usuario\n",
    "    new_descriptors = extract_features(new_fingerprint_path)\n",
    "    if new_descriptors is None:\n",
    "        return \"No se encontraron características en la huella nueva.\"\n",
    "    \n",
    "    max_matches = 0\n",
    "    best_user = None\n",
    "    best_match_path = None\n",
    "\n",
    "    for user_dir in os.listdir(database_dir):\n",
    "        user_path = os.path.join(database_dir, user_dir)\n",
    "        for fingerprint_path in os.listdir(user_path):\n",
    "            full_path = os.path.join(user_path, fingerprint_path)\n",
    "            db_descriptors = extract_features(full_path)\n",
    "\n",
    "            if db_descriptors is None:\n",
    "                continue\n",
    "            \n",
    "            # Compara descriptores para mantener el máximo\n",
    "            match_count = match_fingerprints(new_descriptors, db_descriptors)\n",
    "            print(f\"Comparando con {full_path}, Coincidencias: {match_count}\")\n",
    "\n",
    "            # Actualiza el usuario con más coincidencias\n",
    "            if match_count > max_matches:\n",
    "                max_matches = match_count\n",
    "                best_user = user_dir\n",
    "                best_match_path = full_path\n",
    "\n",
    "    if max_matches >= match_threshold:\n",
    "        return best_user, best_match_path, f\"Huella autenticada como del usuario {best_user} con {max_matches} coincidencias.\"\n",
    "    else:\n",
    "        return best_user, best_match_path, f\"\\nHuella rechazada. Máximas coincidencias: {max_matches}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados obtenidos\n",
    "Calculamos la curva DET para evaluar el rendimiento del sistema, obteniendo las tasas de FPR (falsos positivos) y FNR (falsos negativos) a diferentes umbrales. Además, trazamos la curva y calculamos el ERR (Equal Error Rate), que indica el punto de equilibrio entre ambos errores, proporcionando así una medida del rendimiento de la autenticación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_det(true_labels, scores):\n",
    "    thresholds = sorted(set(scores))\n",
    "    fpr_list = []\n",
    "    fnr_list = []\n",
    "    \n",
    "    # Calcula FPR y FNR para cada umbral\n",
    "    for threshold in thresholds:\n",
    "        tp = fp = tn = fn = 0\n",
    "        for label, score in zip(true_labels, scores):\n",
    "            if score >= threshold:\n",
    "                if label == 1: tp += 1\n",
    "                else: fp += 1\n",
    "            else:\n",
    "                if label == 1: fn += 1\n",
    "                else: tn += 1\n",
    "                \n",
    "        # Calcula tasas de error\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "        fpr_list.append(fpr)\n",
    "        fnr_list.append(fnr)\n",
    "    \n",
    "    return fpr_list, fnr_list\n",
    "\n",
    "# Curva DET\n",
    "def plot_det(fpr, fnr):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, fnr, linestyle='-', label=\"DET Curve\")\n",
    "\n",
    "    # Calcula ERR\n",
    "    eer_index = np.nanargmin(np.abs(np.array(fpr) - np.array(fnr)))\n",
    "    eer = (fpr[eer_index] + fnr[eer_index]) / 2\n",
    "    eer_fpr, eer_fnr = fpr[eer_index], fnr[eer_index]\n",
    "\n",
    "    # Punto EER\n",
    "    plt.scatter(eer_fpr, eer_fnr, color='red', zorder=5, label=f\"ERR: {eer:.4f}\")\n",
    "    plt.annotate(f\"ERR = {eer:.4f}\", \n",
    "                 xy=(eer_fpr, eer_fnr), \n",
    "                 xytext=(eer_fpr + 0.02, eer_fnr + 0.02),\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'),\n",
    "                 fontsize=10)\n",
    "\n",
    "    plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "    plt.ylabel(\"False Negative Rate (FNR)\")\n",
    "    plt.title(\"DET Curve\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Equal Error Rate (ERR): {eer:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecución del código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dir = 'user_database'\n",
    "test_dir = 'user_prueba'\n",
    "\n",
    "# Evalúa las huellas\n",
    "true_labels, scores = evaluate_database(database_dir, test_dir)\n",
    "\n",
    "# Curva DET\n",
    "fpr, fnr = calculate_det(true_labels, scores)\n",
    "plot_det(fpr, fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autentica una huella específica\n",
    "new_fingerprint = 'user_prueba/huella10.png'\n",
    "database_dir = 'user_database'\n",
    "best_user, best_match_path, result = authenticate_user(new_fingerprint, database_dir)\n",
    "print(result)\n",
    "\n",
    "# Visualizamos coincidencias\n",
    "if best_user:\n",
    "    print(f\"\\nVisualizando coincidencias con la huella de {best_user}: {best_match_path}\")\n",
    "    visualize_matches(new_fingerprint, best_match_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
