{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliografía\n",
    "- https://poloclub.github.io/cnn-explainer/ - CNN explainer\n",
    "- https://www.digitalocean.com/community/tutorials/writing-cnns-from-scratch-in-pytorch - Modelo CNN de ejemplo\n",
    "- Modelo preentrenado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def recortar_imagen(input_folder, output_folder, crop_width=550, crop_height=550, threshold_value=225):\n",
    "    \"\"\"\n",
    "    Recorta imágenes de huellas dactilares centradas en el contorno más grande detectado.\n",
    "\n",
    "    Args:\n",
    "        input_folder (str): Carpeta con imágenes de entrada.\n",
    "        output_folder (str): Carpeta donde se guardarán las imágenes recortadas.\n",
    "        crop_width (int): Ancho del recorte deseado.\n",
    "        crop_height (int): Altura del recorte deseado.\n",
    "        threshold_value (int): Umbral para binarización (grises).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if not file.endswith(('.png', '.jpg', '.jpeg')):  # Filtrar tipos de imagen\n",
    "                continue\n",
    "\n",
    "            img_path = os.path.join(root, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if img is None:\n",
    "                print(f\"Error al leer la imagen {img_path}\")\n",
    "                continue\n",
    "\n",
    "            # Binarización de la imagen\n",
    "            _, thresh = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "            # Encontrar contornos\n",
    "            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            if contours:\n",
    "                # Seleccionar el contorno más grande\n",
    "                largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "                # Calcular la caja delimitadora\n",
    "                x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "                # Calcular el centro del contorno\n",
    "                center_x, center_y = x + w // 2, y + h // 2\n",
    "\n",
    "                # Determinar las coordenadas del recorte\n",
    "                x_start = max(center_x - crop_width // 2, 0)\n",
    "                y_start = max(center_y - crop_height // 2, 0)\n",
    "                x_end = min(center_x + crop_width // 2, img.shape[1])\n",
    "                y_end = min(center_y + crop_height // 2, img.shape[0])\n",
    "\n",
    "                # Ajustar el tamaño del recorte si es necesario\n",
    "                if (x_end - x_start) != crop_width:\n",
    "                    x_start = max(0, x_end - crop_width)\n",
    "                if (y_end - y_start) != crop_height:\n",
    "                    y_start = max(0, y_end - crop_height)\n",
    "\n",
    "                # Realizar el recorte\n",
    "                cropped_img = img[y_start:y_end, x_start:x_end]\n",
    "\n",
    "                # Guardar la imagen recortada\n",
    "                output_path = os.path.join(output_folder, file)\n",
    "                cv2.imwrite(output_path, cropped_img)\n",
    "                print(f\"Imagen recortada guardada en {output_path}\")\n",
    "\n",
    "# Uso del método\n",
    "input_folder = 'imagenes_huellas'   # Directorio de imágenes de entrada\n",
    "output_folder = 'imagenes_recortadas'  # Directorio donde se guardarán las imágenes recortadas\n",
    "\n",
    "recortar_imagen(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def procesar_imagen(image_path, output_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"Error: No se pudo cargar la imagen {image_path}.\")\n",
    "        return\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8, 8))\n",
    "    equalized_image = clahe.apply(image)\n",
    "    \n",
    "    bilateral_filtered = cv2.bilateralFilter(equalized_image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    \n",
    "    median_filtered = cv2.medianBlur(bilateral_filtered, 3)\n",
    "    \n",
    "    thresh_image = cv2.adaptiveThreshold(\n",
    "        median_filtered,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        19,\n",
    "        3\n",
    "    )\n",
    "    \n",
    "    inverted_image = cv2.bitwise_not(thresh_image)\n",
    "    \n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned_image = cv2.morphologyEx(inverted_image, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    skeleton = np.zeros(cleaned_image.shape, np.uint8)\n",
    "    img = cleaned_image.copy()\n",
    "    while True:\n",
    "        eroded = cv2.erode(img, None)\n",
    "        temp = cv2.dilate(eroded, None)\n",
    "        temp = cv2.subtract(img, temp)\n",
    "        skeleton = cv2.bitwise_or(skeleton, temp)\n",
    "        img = eroded.copy()\n",
    "        if cv2.countNonZero(img) == 0:\n",
    "            break\n",
    "\n",
    "    cv2.imwrite(output_path, skeleton)\n",
    "    print(f\"Imagen procesada y guardada en {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "input_dir = 'imagenes_recortadas'\n",
    "output_dir = 'imagenes_filtradas'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            image_path = os.path.join(root, file)\n",
    "            output_path = os.path.join(output_dir, file)\n",
    "\n",
    "            procesar_imagen(image_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codigo de david"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrucutra de datos imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Directorio de entrada\n",
    "input_dir = 'imagenes_filtradas'\n",
    "\n",
    "# Directorios de salida\n",
    "output_dir = 'data'\n",
    "os.makedirs(os.path.join(output_dir, 'train/authenticated'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'train/rejected'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'test/authenticated'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'test/rejected'), exist_ok=True)\n",
    "\n",
    "# Separar imágenes de acuerdo a su sufijo\n",
    "train_images = [img for img in os.listdir(input_dir) if 'f' in img]\n",
    "test_images = [img for img in os.listdir(input_dir) if 's' in img]\n",
    "\n",
    "# Etiquetar como autenticadas o rechazadas\n",
    "for idx, image in enumerate(train_images):\n",
    "    if idx < len(train_images) // 2:  # La mitad serán autenticadas\n",
    "        shutil.copy(os.path.join(input_dir, image), os.path.join(output_dir, 'train/authenticated', image))\n",
    "    else:  # La otra mitad serán rechazadas\n",
    "        shutil.copy(os.path.join(input_dir, image), os.path.join(output_dir, 'train/rejected', image))\n",
    "\n",
    "for idx, image in enumerate(test_images):\n",
    "    if idx < len(test_images) // 2:  # La mitad serán autenticadas\n",
    "        shutil.copy(os.path.join(input_dir, image), os.path.join(output_dir, 'test/authenticated', image))\n",
    "    else:  # La otra mitad serán rechazadas\n",
    "        shutil.copy(os.path.join(input_dir, image), os.path.join(output_dir, 'test/rejected', image))\n",
    "\n",
    "print(\"Estructura creada con éxito.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aumento del numero de huellas (muestras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def new_images(input_dir, num_images):\n",
    "    images = [f for f in os.listdir(input_dir) if f.endswith('.png')]\n",
    "    \n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(input_dir, image_name)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            img_copy = img.copy()\n",
    "            \n",
    "            # Rotación aleatoria\n",
    "            angle = random.randint(-90, 90)\n",
    "            h, w = img_copy.shape\n",
    "            center = (w // 2, h // 2)\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            augmented_img = cv2.warpAffine(img_copy, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "            \n",
    "            # Escalado aleatorio\n",
    "            scale_x = random.uniform(0.5, 1.2)\n",
    "            scale_y = random.uniform(0.5, 1.2)\n",
    "            augmented_img = cv2.resize(augmented_img, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            #if input_dir.endswith('rejected'):\n",
    "            # Corte parcial (simulando mal contacto)\n",
    "            x1, y1 = random.randint(0, w // 8), random.randint(0, h // 8)\n",
    "            x2, y2 = random.randint(x1, w // 4), random.randint(y1, h // 4)\n",
    "            cv2.rectangle(augmented_img, (x1, y1), (x2, y2), (0, 0, 0), -1)\n",
    "                \n",
    "            # Traslación aleatoria\n",
    "            max_shift = 10  # Máximo desplazamiento en píxeles\n",
    "            tx = random.randint(-max_shift, max_shift)\n",
    "            ty = random.randint(-max_shift, max_shift)\n",
    "            translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "            augmented_img = cv2.warpAffine(augmented_img, translation_matrix, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "            \n",
    "            # Guardar imagen aumentada en el mismo directorio\n",
    "            output_name = f\"{i}_{image_name}\"\n",
    "            cv2.imwrite(os.path.join(input_dir, output_name), augmented_img)\n",
    "\n",
    "# Directorios de train y test\n",
    "train_authenticated_dir = 'data/train/authenticated'\n",
    "test_authenticated_dir = 'data/test/authenticated'\n",
    "train_rejected_dir = 'data/train/rejected'\n",
    "test_rejected_dir = 'data/test/rejected'\n",
    "\n",
    "for directory in [train_authenticated_dir, test_authenticated_dir, train_rejected_dir, test_rejected_dir]:\n",
    "        new_images(directory, num_images=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetamos las huellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Transformaciones para entrenamiento (con data augmentation dinámico)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Convertir a escala de grises\n",
    "    transforms.Resize((224, 224)),  # Redimensionar a 128x128\n",
    "    transforms.RandomRotation(degrees=360),  # Rotación aleatoria entre -360 y 360 grados\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Volteo horizontal con probabilidad 50%\n",
    "    transforms.RandomVerticalFlip(p=0.5),  # Volteo vertical con probabilidad 50%\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Traslación aleatoria (10% en ambas direcciones)\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.25),  # Perspectiva aleatoria\n",
    "    transforms.ToTensor(),  # Convertir a tensor\n",
    "    #transforms.RandomErasing(p=0.25, scale=(0.01, 0.1), ratio=(0.5, 2.0)),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalización\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Convertir a escala de grises\n",
    "    transforms.Resize((224, 224)),  # Redimensionar\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalización\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Dataset personalizado\n",
    "class FingerprintDataset(Dataset):\n",
    "    def __init__(self, directory, transform):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "\n",
    "        # Leer las imágenes y sus etiquetas según las subcarpetas\n",
    "        for label, subfolder in enumerate(['authenticated', 'rejected']):\n",
    "            subfolder_path = os.path.join(directory, subfolder)\n",
    "            if os.path.exists(subfolder_path):  # Verificar que la subcarpeta exista\n",
    "                for img_name in os.listdir(subfolder_path):\n",
    "                    if img_name.endswith('.png'):\n",
    "                        img_path = os.path.join(subfolder_path, img_name)\n",
    "                        self.data.append((img_path, label))  # Añadir la ruta de la imagen y la etiqueta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Cargar datasets\n",
    "train_dataset = FingerprintDataset(directory='data/train', transform=train_transform)\n",
    "test_dataset = FingerprintDataset(directory='data/test', transform=test_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Verificar las etiquetas en el DataLoader\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)  # Dimensiones del lote de imágenes\n",
    "    print(labels)  # Etiquetas: 0 (autenticadas), 1 (rechazadas)\n",
    "    break  # Mostrar solo un lote\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# CNN mejorada\n",
    "class FingerprintCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FingerprintCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Bloque 1\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 1 canal de entrada (grises)\n",
    "            nn.BatchNorm2d(32),  # Batch Normalization\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Reduce tamaño a la mitad\n",
    "            \n",
    "            # Bloque 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Bloque 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Bloque 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # Reduce tamaño final\n",
    "        )\n",
    "        \n",
    "        # Calcula el tamaño dinámico del tensor después de las convoluciones\n",
    "        self._calculate_flatten_size()\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),  # Aplanar la salida de las convoluciones\n",
    "            nn.Linear(self.flattened_size, 512),  # Ajustar según el tamaño final de los mapas de características\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.5),  # Regularización\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Dropout(0.5),  # Regularización\n",
    "            \n",
    "            nn.Linear(256, 1),  # Una salida binaria\n",
    "            nn.Sigmoid()  # Activación entre 0 y 1\n",
    "        )\n",
    "    \n",
    "    def _calculate_flatten_size(self):\n",
    "            with torch.no_grad():\n",
    "                dummy_input = torch.zeros(1, 1, 224, 224)  # Tamaño de entrada esperado\n",
    "                conv_out = self.conv_layers(dummy_input)\n",
    "                self.flattened_size = conv_out.numel()  # Calcula el tamaño después de las convoluciones\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del dispositivo (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando dispositivo: {device}')\n",
    "\n",
    "model = FingerprintCNN().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss para clasificación binaria\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Poner el modelo en modo entrenamiento\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device).float()  # Convertir etiquetas a float\n",
    "        \n",
    "        # Adelante\n",
    "        outputs = model(images).squeeze(1)  # Eliminar dimensión extra de la salida\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Atrás\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_curve, auc, det_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Modo evaluación\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "\n",
    "with torch.no_grad():  # No necesitamos gradientes para evaluación\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).squeeze(1)\n",
    "        predicted = (outputs > 0.7).float()  # Umbral: salida > 0.7 es 1 (authenticated)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_probabilities.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Calcular el F1-score\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy en conjunto de prueba: {accuracy:.2f}%\")\n",
    "print(f\"Total de imágenes: {total}, Correctas: {correct}, Incorrectas: {total - correct}\")\n",
    "\n",
    "# Calcular la curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Línea base\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Graficar la función de densidad de probabilidad\n",
    "def plot_probability_density(labels, probabilities):\n",
    "    sns.kdeplot(np.array(probabilities)[np.array(labels) == 1], label='Autenticadas (1)', shade=True)\n",
    "    sns.kdeplot(np.array(probabilities)[np.array(labels) == 0], label='Rechazadas (0)', shade=True)\n",
    "    plt.title('Densidad de Probabilidad')\n",
    "    plt.xlabel('Probabilidad Predicha')\n",
    "    plt.ylabel('Densidad')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_probability_density(all_labels, all_probabilities)\n",
    "\n",
    "# Graficar la curva DET\n",
    "def plot_det_curve(labels, probabilities):\n",
    "    fpr, fnr, _ = det_curve(labels, probabilities)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, fnr, label='Curva DET', color='blue')\n",
    "    plt.title('Curva DET')\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('False Negative Rate (FNR)')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_det_curve(all_labels, all_probabilities)\n",
    "\n",
    "# Calcular y mostrar el EER (Equal Error Rate)\n",
    "def calculate_eer(labels, probabilities):\n",
    "    fpr, tpr, thresholds = roc_curve(labels, probabilities)\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = thresholds[np.nanargmin(np.abs(fpr - fnr))]\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - fnr))]\n",
    "    print(f\"EER: {eer:.2f} (Threshold: {eer_threshold:.2f})\")\n",
    "    return eer, eer_threshold\n",
    "\n",
    "eer, eer_threshold = calculate_eer(all_labels, all_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Asegurarte de que el modelo esté en modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# Obtener un lote del conjunto de entrenamiento\n",
    "images, labels = next(iter(train_loader))  # Cambia `train_loader` por `test_loader` si prefieres\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# Realizar predicciones\n",
    "with torch.no_grad():  # Desactiva el cálculo del gradiente para mayor eficiencia\n",
    "    outputs = model(images).squeeze(1)  # Predicciones del modelo\n",
    "    predictions = (outputs >= 0.7).float()  # Clasifica como 1 si probabilidad >= 0.7, de lo contrario 0\n",
    "\n",
    "# Visualizar las imágenes con sus etiquetas reales y predichas\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 8))\n",
    "for i, ax in enumerate(axes):\n",
    "    img = images[i].cpu().squeeze().numpy()  # Convertir tensor a NumPy\n",
    "    real_label = labels[i].item()  # Etiqueta real\n",
    "    predicted_label = predictions[i].item()  # Etiqueta predicha\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"Real: {real_label}, Pred: {predicted_label}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Etiquetas reales: \", labels.cpu().numpy())\n",
    "print(\"Etiquetas predichas: \", predictions.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Clasificar una nueva huella\n",
    "def classify_fingerprint(model, image_path, transform):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('L')  # Escala de grises\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Añadir dimensión de batch\n",
    "    with torch.no_grad():\n",
    "        output = model(image).item()\n",
    "    return \"Authenticated\" if output > 0.8 else \"Rejected\"\n",
    "\n",
    "# Ruta de la nueva huella\n",
    "new_fingerprint_path = 'user_prueba/huella6.png'\n",
    "result = classify_fingerprint(model, new_fingerprint_path, test_transform)\n",
    "print(f\"Resultado de la clasificación: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
