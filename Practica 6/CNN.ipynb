{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def filtrar_huellas(imagen):\n",
    "    imagen_gris = cv.cvtColor(imagen, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    imagen_filtrada = cv.medianBlur(imagen_gris, 5)\n",
    "    \n",
    "    imagen_clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(imagen_filtrada)\n",
    "\n",
    "    imagen_binaria = cv.adaptiveThreshold(\n",
    "        imagen_clahe,\n",
    "        255,\n",
    "        cv.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv.THRESH_BINARY,\n",
    "        11,\n",
    "        10\n",
    "    )\n",
    "\n",
    "    imagen_binaria = cv.medianBlur(imagen_binaria, 3)\n",
    "    \n",
    "    return imagen_binaria\n",
    "\n",
    "sample_path = \"imagenes_huellas\"\n",
    "files = os.listdir(sample_path)\n",
    "\n",
    "for file in files:\n",
    "    dir = os.path.join(sample_path, file)\n",
    "    file2 = os.listdir(dir)\n",
    "    ruta = os.path.join(dir, file2[0])\n",
    "    sample = cv.imread(ruta)  \n",
    "    sample = filtrar_huellas(sample)\n",
    "\n",
    "cv.imshow('Huellas', sample)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = 'imagenes_huellas/crd_0820f/crd_0820s_01.png'\n",
    "image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: No se pudo cargar la imagen.\")\n",
    "else:\n",
    "    print(\"Imagen cargada correctamente.\")\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    equalized_image = clahe.apply(image)\n",
    "    \n",
    "    blurred_image = cv2.GaussianBlur(equalized_image, (5, 5), 0)\n",
    "    \n",
    "    thresh_image = cv2.adaptiveThreshold(\n",
    "        blurred_image,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        11,\n",
    "        10\n",
    "    )\n",
    "    \n",
    "    inverted_image = cv2.bitwise_not(thresh_image)\n",
    "\n",
    "    cv2.imshow('Imagen', inverted_image)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.title('Imagen Original')\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.subplot(2, 3, 2)\n",
    "    plt.title('Ecualización de Histograma (CLAHE)')\n",
    "    plt.imshow(equalized_image, cmap='gray')\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.title('Imagen Desenfocada (Filtro Gaussiano)')\n",
    "    plt.imshow(blurred_image, cmap='gray')\n",
    "    plt.subplot(2, 3, 4)\n",
    "    plt.title('Umbral Adaptativo')\n",
    "    plt.imshow(inverted_image, cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "input_folder = 'imagenes_huellas'\n",
    "output_folder = 'imagenes_recortadas'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "crop_width, crop_height = 550, 550  # Ajusta el tamaño del recorte deseado\n",
    "\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        img_path = os.path.join(root, file)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"Error al leer la imagen {img_path}\")\n",
    "            continue\n",
    "\n",
    "        _, thresh = cv2.threshold(img, 225, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "            center_x, center_y = x + w // 2, y + h // 2\n",
    "\n",
    "            x_start = max(center_x - crop_width // 2, 0)\n",
    "            y_start = max(center_y - crop_height // 2, 0)\n",
    "            x_end = min(center_x + crop_width // 2, img.shape[1])\n",
    "            y_end = min(center_y + crop_height // 2, img.shape[0])\n",
    "\n",
    "            if (x_end - x_start) != crop_width:\n",
    "                x_start = max(0, x_end - crop_width)\n",
    "            if (y_end - y_start) != crop_height:\n",
    "                y_start = max(0, y_end - crop_height)\n",
    "\n",
    "            cropped_img = img[y_start:y_end, x_start:x_end]\n",
    "\n",
    "            output_path = os.path.join(output_folder, file)\n",
    "            cv2.imwrite(output_path, cropped_img)\n",
    "            print(f\"Imagen recortada guardada en {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "input_dir = 'imagenes_recortadas'\n",
    "output_dir = 'imagenes_filtradas'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def procesar_imagen(image_path, output_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"Error: No se pudo cargar la imagen {image_path}.\")\n",
    "        return\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8, 8))\n",
    "    equalized_image = clahe.apply(image)\n",
    "    \n",
    "    bilateral_filtered = cv2.bilateralFilter(equalized_image, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "    \n",
    "    median_filtered = cv2.medianBlur(bilateral_filtered, 3)\n",
    "    \n",
    "    thresh_image = cv2.adaptiveThreshold(\n",
    "        median_filtered,\n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        19,\n",
    "        3\n",
    "    )\n",
    "    \n",
    "    inverted_image = cv2.bitwise_not(thresh_image)\n",
    "    \n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned_image = cv2.morphologyEx(inverted_image, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    skeleton = np.zeros(cleaned_image.shape, np.uint8)\n",
    "    img = cleaned_image.copy()\n",
    "    while True:\n",
    "        eroded = cv2.erode(img, None)\n",
    "        temp = cv2.dilate(eroded, None)\n",
    "        temp = cv2.subtract(img, temp)\n",
    "        skeleton = cv2.bitwise_or(skeleton, temp)\n",
    "        img = eroded.copy()\n",
    "        if cv2.countNonZero(img) == 0:\n",
    "            break\n",
    "\n",
    "    cv2.imwrite(output_path, skeleton)\n",
    "    print(f\"Imagen procesada y guardada en {output_path}\")\n",
    "\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.png'):\n",
    "            image_path = os.path.join(root, file)\n",
    "            output_path = os.path.join(output_dir, file)\n",
    "\n",
    "            procesar_imagen(image_path, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codigo de david"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrucutra de datos imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Directorio de entrada\n",
    "input_dir = 'imagenes_filtradas'\n",
    "\n",
    "# Directorio de salida\n",
    "output_dir = 'data'\n",
    "os.makedirs(os.path.join(output_dir, 'train/authenticated'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'train/rejected'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'test/authenticated'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'test/rejected'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'validation/authenticated'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'validation/rejected'), exist_ok=True)\n",
    "\n",
    "# Iterar por las imágenes\n",
    "for image in os.listdir(input_dir):\n",
    "    # Validar imágenes para autenticadas (s) y rechazadas (f) de la huella 20\n",
    "    if '20' in image and 's' in image:\n",
    "        shutil.copy(os.path.join(input_dir, image), os.path.join(output_dir, 'validation/authenticated', image))\n",
    "    \n",
    "    elif '20' in image and 'f' in image:\n",
    "        shutil.copy(os.path.join(input_dir, image), os.path.join(output_dir, 'validation/rejected', image))\n",
    "    \n",
    "    # Imágenes para entrenamiento (train) o prueba (test)\n",
    "    elif 's' in image:\n",
    "        shutil.copy(os.path.join(input_dir, image), os.path.join(output_dir, 'train/authenticated', image))\n",
    "    elif 'f' in image:\n",
    "        shutil.copy(os.path.join(input_dir, image), os.path.join(output_dir, 'test/authenticated', image))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aumento del numero de huellas (muestras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def new_images(input_dir, num_images):\n",
    "    images = [f for f in os.listdir(input_dir) if f.endswith('.png')]\n",
    "    \n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(input_dir, image_name)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            img_copy = img.copy()\n",
    "            \n",
    "            # Rotación aleatoria\n",
    "            angle = random.randint(-10, 10)\n",
    "            h, w = img_copy.shape\n",
    "            center = (w // 2, h // 2)\n",
    "            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            augmented_img = cv2.warpAffine(img_copy, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "            \n",
    "            # Escalado aleatorio\n",
    "            scale_x = random.uniform(0.8, 1.2)\n",
    "            scale_y = random.uniform(0.8, 1.2)\n",
    "            augmented_img = cv2.resize(augmented_img, None, fx=scale_x, fy=scale_y, interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            # Traslación aleatoria\n",
    "            max_shift = 10  # Máximo desplazamiento en píxeles\n",
    "            tx = random.randint(-max_shift, max_shift)\n",
    "            ty = random.randint(-max_shift, max_shift)\n",
    "            translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "            augmented_img = cv2.warpAffine(augmented_img, translation_matrix, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "            \n",
    "            # Guardar imagen aumentada en el mismo directorio\n",
    "            output_name = f\"{i}_{image_name}\"\n",
    "            cv2.imwrite(os.path.join(input_dir, output_name), augmented_img)\n",
    "\n",
    "# Directorios de autenticadas\n",
    "train_authenticated_dir = 'data/train/authenticated'\n",
    "test_authenticated_dir = 'data/test/authenticated'\n",
    "train_rejected_dir = 'data/train/rejected'\n",
    "test_rejected_dir = 'data/test/rejected'\n",
    "\n",
    "# Augmentación de imágenes autenticadas\n",
    "new_images(train_authenticated_dir, num_images=10)\n",
    "new_images(test_authenticated_dir, num_images=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aumento de numero de muestras falsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def new_rejected_images(authenticated_dir, rejected_dir, num_images):\n",
    "    os.makedirs(rejected_dir, exist_ok=True)\n",
    "    images = [f for f in os.listdir(authenticated_dir) if f.endswith('.png')]\n",
    "    \n",
    "    for image_name in images:\n",
    "        image_path = os.path.join(authenticated_dir, image_name)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            rejected_img = img.copy()\n",
    "            \n",
    "            # Seleccionar una transformación aleatoria\n",
    "            transformation = random.choice(['erase', 'blur', 'heavy_noise'])\n",
    "            \n",
    "            if transformation == 'erase':\n",
    "                # Eliminar un cuadrado centrado en la imagen\n",
    "                h, w = rejected_img.shape\n",
    "                \n",
    "                # Tamaño del lado del cuadrado (ajustable)\n",
    "                square_size = min(w, h) // 32  \n",
    "                \n",
    "                # Coordenadas del centro de la imagen\n",
    "                center_x, center_y = w // 2, h // 2\n",
    "                \n",
    "                # Coordenadas del cuadrado alrededor del centro\n",
    "                x1 = center_x - square_size // 2\n",
    "                y1 = center_y - square_size // 2\n",
    "                x2 = center_x + square_size // 2\n",
    "                y2 = center_y + square_size // 2\n",
    "                \n",
    "                # Dibujar un cuadrado negro\n",
    "                cv2.rectangle(rejected_img, (x1, y1), (x2, y2), (0, 0, 0), -1)\n",
    "                            \n",
    "            elif transformation == 'blur':\n",
    "                # Aplicar desenfoque extremo\n",
    "                kernel_size = random.choice([15, 21, 25])  # Tamaño del kernel\n",
    "                rejected_img = cv2.GaussianBlur(rejected_img, (kernel_size, kernel_size), 0)\n",
    "            \n",
    "            elif transformation == 'heavy_noise':\n",
    "                # Agregar ruido severo\n",
    "                noise = np.random.randint(0, 20, rejected_img.shape, dtype='uint8')\n",
    "                rejected_img = cv2.add(rejected_img, noise)\n",
    "            \n",
    "            # Guardar imagen generada\n",
    "            output_name = f\"rej_{i}_{image_name}\"\n",
    "            cv2.imwrite(os.path.join(rejected_dir, output_name), rejected_img)\n",
    "\n",
    "# Directorios\n",
    "train_authenticated_dir = 'data/train/authenticated'\n",
    "train_rejected_dir = 'data/train/rejected'\n",
    "\n",
    "test_authenticated_dir = 'data/test/authenticated'\n",
    "test_rejected_dir = 'data/test/rejected'\n",
    "\n",
    "# Generar datos rechazados más complejos\n",
    "new_rejected_images(train_authenticated_dir, train_rejected_dir, num_images=1)\n",
    "new_rejected_images(test_authenticated_dir, test_rejected_dir, num_images=1)\n",
    "\n",
    "new_images(train_rejected_dir, num_images=1)\n",
    "new_images(test_rejected_dir, num_images=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetamos las huellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Asegurar escala de grises\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Cargar datasets\n",
    "train_dataset = datasets.ImageFolder('data/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('data/test', transform=transform)\n",
    "\n",
    "# Cargar en DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True) # Batch_size en funcion del tamaño de los datos\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Etiquetas automáticas\n",
    "print(train_dataset.class_to_idx)  # {'authenticated': 0, 'rejected': 1}\n",
    "print(test_dataset.class_to_idx, \"\\n\")  # {'authenticated': 0, 'rejected': 1}\n",
    "\n",
    "# Verificar tamaño de los datos\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape, labels.shape)  # torch.Size([8, 1, 128, 128]) torch.Size([8])\n",
    "print(labels, \"\\n\")\n",
    "\n",
    "images, labels = next(iter(test_loader))\n",
    "print(images.shape, labels.shape)  # torch.Size([8, 1, 128, 128]) torch.Size([8])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN\n",
    "https://www.digitalocean.com/community/tutorials/writing-cnns-from-scratch-in-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pegarlo aqui y cambiar las dimensiones para que funcionen con las imagenes de 128x128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Definir la arquitectura de la CNN\n",
    "class FingerprintCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FingerprintCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),  # 1 = imágenes en escala de grises\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Reduce tamaño a la mitad\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 16 * 16, 256),  # Ajusta 16x16 si las imágenes son de 128x128\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # Ayuda a evitar el sobreajuste\n",
    "            nn.Linear(256, 1),  # Una salida para clasificación binaria\n",
    "            nn.Sigmoid() # Salida entre 0 y 1\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del dispositivo (GPU si está disponible)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando dispositivo: {device}')\n",
    "\n",
    "model = FingerprintCNN().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss para clasificación binaria\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Ciclo de entrenamiento\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Poner el modelo en modo entrenamiento\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device).float()  # Convertir etiquetas a float\n",
    "        \n",
    "        # Adelante\n",
    "        outputs = model(images).squeeze(1)  # Eliminar dimensión extra de la salida\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Atrás\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_curve, auc\n",
    "\n",
    "# Modo evaluación\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "\n",
    "with torch.no_grad():  # No necesitamos gradientes para evaluación\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).squeeze(1)\n",
    "        predicted = (outputs > 0.7).float()  # Umbral: salida > 0.8 es 1 (authenticated)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_probabilities.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Calcular el F1-score\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy en conjunto de prueba: {accuracy:.2f}%\")\n",
    "print(f\"Total de imágenes: {total}, Correctas: {correct}, Incorrectas: {total - correct}\")\n",
    "\n",
    "# Calcular la curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Línea base\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizar un lote del conjunto de entrenamiento\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"Shape de las imágenes:\", images.shape)  # torch.Size([batch_size, 1, 128, 128])\n",
    "print(\"Etiquetas:\", labels)  # Ejemplo: tensor([0, 1, 0, 0, 1])\n",
    "\n",
    "# Mostrar las primeras 8 imágenes con sus etiquetas\n",
    "fig, axes = plt.subplots(1, 8, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    img = images[i].squeeze().numpy()  # Convertir tensor a numpy\n",
    "    label = labels[i].item()\n",
    "    # Clase basada en class_to_idx\n",
    "    clase = [k for k, v in train_dataset.class_to_idx.items() if v == label][0]\n",
    "    print(f\"Etiqueta: {label}, Clase: {clase}\")\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"Etiqueta: {label}\")\n",
    "    ax.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Configurar el modelo en modo de evaluación\n",
    "model.eval()\n",
    "\n",
    "# Transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Asegurar escala de grises\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Directorio de validación\n",
    "validation_dir = 'data/validation'\n",
    "\n",
    "# Listar carpetas de validación\n",
    "folders = {\n",
    "    'authenticated': os.path.join(validation_dir, 'authenticated'),\n",
    "    'rejected': os.path.join(validation_dir, 'rejected')\n",
    "}\n",
    "\n",
    "# Validar las imágenes de la huella 20\n",
    "results = []\n",
    "for label, folder in folders.items():\n",
    "    for img_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # Preprocesar la imagen\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)  # Añadir dimensión de batch\n",
    "        \n",
    "        # Realizar la predicción\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor).item()\n",
    "            prediction = \"authenticated\" if output <= 0.8 else \"rejected\"\n",
    "        \n",
    "        # Guardar el resultado\n",
    "        results.append({\n",
    "            'image': img_name,\n",
    "            'label': label,\n",
    "            'prediction': prediction,\n",
    "            'probability': output\n",
    "        })\n",
    "\n",
    "# Mostrar resultados\n",
    "for result in results:\n",
    "    print(f\"Imagen: {result['image']}, Etiqueta Real: {result['label']}, Predicción: {result['prediction']}, Probabilidad: {result['probability']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN preentrenado (ResNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Transformaciones para el dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convertir a 3 canales (los modelos preentrenados esperan RGB)\n",
    "    transforms.Resize((224, 224)),  # Tamaño estándar para modelos preentrenados como ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalización para modelos preentrenados\n",
    "])\n",
    "\n",
    "# Cargar datasets\n",
    "train_dataset = datasets.ImageFolder('data/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('data/test', transform=transform)\n",
    "validation_dataset = datasets.ImageFolder('data/validation', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Cargar un modelo preentrenado\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modificar la última capa para clasificación binaria\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 1),  # Una salida para clasificación binaria\n",
    "    nn.Sigmoid()  # Escalar la salida a [0, 1]\n",
    ")\n",
    "\n",
    "# Mover el modelo al dispositivo\n",
    "model = model.to(device)\n",
    "\n",
    "# Congelar capas iniciales (opcional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Entrenar solo la última capa\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Función de pérdida y optimizador\n",
    "criterion = nn.BCELoss()  # Para clasificación binaria\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device).float()  # Convertir etiquetas a float\n",
    "        \n",
    "        # Adelante\n",
    "        outputs = model(images).squeeze(1)  # Salida del modelo\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Atrás\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluación del modelo\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).squeeze(1)\n",
    "        predicted = (outputs > 0.8).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Precisión en el conjunto de prueba: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Configurar el modelo en modo de evaluación\n",
    "model.eval()\n",
    "\n",
    "# Directorio de validación\n",
    "validation_dir = 'data/validation'\n",
    "\n",
    "# Listar carpetas de validación\n",
    "folders = {\n",
    "    'authenticated': os.path.join(validation_dir, 'authenticated'),\n",
    "    'rejected': os.path.join(validation_dir, 'rejected')\n",
    "}\n",
    "\n",
    "# Validar las imágenes de la huella 20\n",
    "results = []\n",
    "for label, folder in folders.items():\n",
    "    for img_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # Preprocesar la imagen\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)  # Añadir dimensión de batch\n",
    "        \n",
    "        # Realizar la predicción\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor).item()\n",
    "            prediction = \"authenticated\" if output <= 0.5 else \"rejected\"\n",
    "        \n",
    "        # Guardar el resultado\n",
    "        results.append({\n",
    "            'image': img_name,\n",
    "            'label': label,\n",
    "            'prediction': prediction,\n",
    "            'probability': output\n",
    "        })\n",
    "\n",
    "# Mostrar resultados\n",
    "for result in results:\n",
    "    print(f\"Imagen: {result['image']}, Etiqueta Real: {result['label']}, Predicción: {result['prediction']}, Probabilidad: {result['probability']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo CNN con EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configuración del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Transformaciones para el dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convertir imágenes a 3 canales (para modelos preentrenados)\n",
    "    transforms.Resize((224, 224)),  # Tamaño estándar para EfficientNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalización para ImageNet\n",
    "])\n",
    "\n",
    "# Cargar datasets\n",
    "train_dataset = datasets.ImageFolder('data/train', transform=transform)\n",
    "test_dataset = datasets.ImageFolder('data/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Cargar EfficientNet-B0 preentrenado\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Modificar la última capa para clasificación binaria\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, 1),  # Una salida para clasificación binaria\n",
    "    nn.Sigmoid()  # Escala la salida a [0, 1]\n",
    ")\n",
    "\n",
    "# Mover el modelo al dispositivo\n",
    "model = model.to(device)\n",
    "\n",
    "# Congelar capas iniciales (opcional)\n",
    "for param in model.features.parameters():  # Congelar solo las capas convolucionales\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Optimización y pérdida\n",
    "criterion = nn.BCELoss()  # Para clasificación binaria\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)  # Entrenar solo la última capa\n",
    "\n",
    "# Ciclo de entrenamiento\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device).float()  # Convertir etiquetas a float\n",
    "        \n",
    "        # Adelante\n",
    "        outputs = model(images).squeeze(1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Atrás\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Evaluación del modelo\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).squeeze(1)\n",
    "        predicted = (outputs > 0.5).long()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Precisión en el conjunto de prueba: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Configurar el modelo en modo de evaluación\n",
    "model.eval()\n",
    "\n",
    "# Directorio de validación\n",
    "validation_dir = 'data/validation'\n",
    "\n",
    "# Listar carpetas de validación\n",
    "folders = {\n",
    "    'authenticated': os.path.join(validation_dir, 'authenticated'),\n",
    "    'rejected': os.path.join(validation_dir, 'rejected')\n",
    "}\n",
    "\n",
    "# Validar las imágenes de la huella 20\n",
    "results = []\n",
    "for label, folder in folders.items():\n",
    "    for img_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # Preprocesar la imagen, TRANSFORM DEFINIDO ARRIBA\n",
    "        input_tensor = transform(image).unsqueeze(0).to(device)  # Añadir dimensión de batch\n",
    "        \n",
    "        # Realizar la predicción\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor).item()\n",
    "            prediction = \"authenticated\" if output <= 0.5 else \"rejected\"\n",
    "        \n",
    "        # Guardar el resultado\n",
    "        results.append({\n",
    "            'image': img_name,\n",
    "            'label': label,\n",
    "            'prediction': prediction,\n",
    "            'probability': output\n",
    "        })\n",
    "\n",
    "# Mostrar resultados\n",
    "for result in results:\n",
    "    print(f\"Imagen: {result['image']}, Etiqueta Real: {result['label']}, Predicción: {result['prediction']}, Probabilidad: {result['probability']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "piav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
